{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElemNet: A formation energy prediction tool from elemental composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A formation energy prediction tool using 17-layered deep neural network that achieves an accuracy of 0.042 on the Open Quantum Materials Database (OQMD).\n",
    "### Input: Takes a 2D numpy array with the rows representing different compounds, and columns representing the elemental compositions with 86 elements in the set elements- ['H', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu'], elemental compositon does not contain any element from ['He', 'Ne', 'Ar', 'Po', 'At','Rn','Fr','Ra']\n",
    "### Output: Returns a 1D numpy array with the predicted formation energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "import time, os, re\n",
    "from collections import OrderedDict, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elements = ['H', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'K', 'Ca', 'Sc', 'Ti', 'V', \n",
    "            'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', \n",
    "            'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', \n",
    "            'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', \n",
    "            'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formulare = re.compile(r'([A-Z][a-z]*)(\\d*)')\n",
    "def parse_formula(formula):\n",
    "    pairs = formulare.findall(formula)\n",
    "    length = sum((len(p[0]) + len(p[1]) for p in pairs))\n",
    "    assert length == len(formula)\n",
    "    formula_dict = defaultdict(int)\n",
    "    for el, sub in pairs:\n",
    "        formula_dict[el] += float(sub) if sub else 1\n",
    "    return formula_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formulas = ['H2O','NaCl', 'H2SO4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[defaultdict(<class 'int'>, {'H': 2.0, 'O': 1}), defaultdict(<class 'int'>, {'Na': 1, 'Cl': 1}), defaultdict(<class 'int'>, {'H': 2.0, 'S': 1, 'O': 4.0})]\n"
     ]
    }
   ],
   "source": [
    "formulas = [parse_formula(x) for x in formulas]\n",
    "print(formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = np.zeros(shape=(len(formulas), 86), dtype=np.float32)\n",
    "i = -1\n",
    "for formula in formulas:\n",
    "    i+=1\n",
    "    keys = formula.keys()\n",
    "    values = formula.values()\n",
    "    total = float(sum(values))\n",
    "    for k in keys:\n",
    "        input[i][elements.index(k)] = formula[k]/total\n",
    "data = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = data\n",
    "test_y = np.zeros((86), np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "architecture = '1024x4D-512x3D-256x3D-128x3D-64x2-32x1-1'\n",
    "activation = 'relu'\n",
    "dropouts = [0.8, 0.9, 0.7, 0.8]\n",
    "SEED = 66478\n",
    "num_input = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def model_slim(data, architecture, train=True, num_labels=1, activation='relu', dropouts=dropouts):\n",
    "        if train:\n",
    "            reuse = None\n",
    "        else:\n",
    "            reuse = True\n",
    "\n",
    "        if activation == 'relu':\n",
    "            activation = tf.nn.relu\n",
    "        assert '-' in architecture\n",
    "        archs = architecture.strip().split('-')\n",
    "        net = data\n",
    "        pen_layer = net\n",
    "        prev_layer = net\n",
    "        prev_num_outputs = None\n",
    "        prev_block_num_outputs = None\n",
    "        prev_stub_output = net\n",
    "        for i in range(len(archs)):\n",
    "            arch = archs[i]\n",
    "            if 'x' in arch:\n",
    "                arch = arch.split('x')\n",
    "                num_outputs = int(re.findall(r'\\d+',arch[0])[0])\n",
    "                layers = int(re.findall(r'\\d+',arch[1])[0])\n",
    "                j = 0\n",
    "                aux_layers = re.findall(r'[A-Z]',arch[0])\n",
    "                for l in range(layers):\n",
    "                    if aux_layers and aux_layers[0] == 'B':\n",
    "                        if len(aux_layers)>1 and aux_layers[1]=='A':\n",
    "                            print('adding fully connected layers with %d outputs followed by batch_norm and act' % num_outputs)\n",
    "\n",
    "                            net = slim.layers.fully_connected(net, num_outputs=num_outputs,\n",
    "                                                              scope='fc' + str(i) + '_' + str(j),\n",
    "                                                              activation_fn=None, reuse=reuse)\n",
    "                            net = slim.layers.batch_norm(net, center=True, scale=True, reuse=reuse, scope='fc_bn'+str(i)+'_'+str(j))\n",
    "                            net = activation(net)\n",
    "                        else:\n",
    "                            print('adding fully connected layers with %d outputs followed by batch_norm' % num_outputs)\n",
    "                            net = slim.layers.fully_connected(net, num_outputs=num_outputs,\n",
    "                                                              scope='fc' + str(i) + '_' + str(j),\n",
    "                                                              activation_fn=activation, reuse=reuse)\n",
    "                            net = slim.layers.batch_norm(net, center=True, scale=True, reuse=reuse,\n",
    "                                             scope='fc_bn' + str(i) + '_' + str(j))\n",
    "\n",
    "                    else:\n",
    "                        print('adding fully connected layers with %d outputs' % num_outputs)\n",
    "\n",
    "                        net = slim.layers.fully_connected(net, num_outputs=num_outputs,\n",
    "                                                          scope='fc' + str(i) + '_' + str(j), activation_fn=activation,\n",
    "                                                              reuse=reuse)\n",
    "                    if 'R' in aux_layers:\n",
    "                        if prev_num_outputs and prev_num_outputs==num_outputs:\n",
    "                            print('adding residual, both sizes are same')\n",
    "\n",
    "                            net = net+prev_layer\n",
    "                        else:\n",
    "                            print('adding residual with fc as the size are different')\n",
    "                            net = net + slim.layers.fully_connected(prev_layer, num_outputs=num_outputs,\n",
    "                                                                  scope='fc' + str(i) + '_' +'dim_'+ str(j),\n",
    "                                                          activation_fn=None, reuse=reuse)\n",
    "                    prev_num_outputs = num_outputs\n",
    "                    j += 1\n",
    "                    prev_layer = net\n",
    "                aux_layers_sub = re.findall(r'[A-Z]', arch[1])\n",
    "                if 'D' in aux_layers_sub and (train or num_labels == 1) and len(dropouts) > i:\n",
    "                    print('adding dropout', dropouts[i])\n",
    "                    net = tf.nn.dropout(net, dropouts[i], seed=SEED)\n",
    "                prev_stub_output = net\n",
    "                prev_block_num_outputs = num_outputs\n",
    "                prev_layer = net\n",
    "\n",
    "            else:\n",
    "                if 'R' in arch:\n",
    "                    act_fun = tf.nn.relu\n",
    "                    print('using ReLU at last layer')\n",
    "                else:\n",
    "                    act_fun = None\n",
    "                pen_layer = net\n",
    "                print('adding final layer with ' + str(num_labels) + ' output')\n",
    "                net = slim.layers.fully_connected(net, num_outputs=num_labels, scope='fc' + str(i),\n",
    "                                                  activation_fn=act_fun, reuse=reuse)\n",
    "\n",
    "        net = tf.squeeze(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding dropout 0.8\n",
      "adding fully connected layers with 512 outputs\n",
      "adding fully connected layers with 512 outputs\n",
      "adding fully connected layers with 512 outputs\n",
      "adding dropout 0.9\n",
      "adding fully connected layers with 256 outputs\n",
      "adding fully connected layers with 256 outputs\n",
      "adding fully connected layers with 256 outputs\n",
      "adding dropout 0.7\n",
      "adding fully connected layers with 128 outputs\n",
      "adding fully connected layers with 128 outputs\n",
      "adding fully connected layers with 128 outputs\n",
      "adding dropout 0.8\n",
      "adding fully connected layers with 64 outputs\n",
      "adding fully connected layers with 64 outputs\n",
      "adding fully connected layers with 32 outputs\n",
      "adding final layer with 1 output\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding fully connected layers with 1024 outputs\n",
      "adding dropout 0.8\n",
      "adding fully connected layers with 512 outputs\n",
      "adding fully connected layers with 512 outputs\n",
      "adding fully connected layers with 512 outputs\n",
      "adding dropout 0.9\n",
      "adding fully connected layers with 256 outputs\n",
      "adding fully connected layers with 256 outputs\n",
      "adding fully connected layers with 256 outputs\n",
      "adding dropout 0.7\n",
      "adding fully connected layers with 128 outputs\n",
      "adding fully connected layers with 128 outputs\n",
      "adding fully connected layers with 128 outputs\n",
      "adding dropout 0.8\n",
      "adding fully connected layers with 64 outputs\n",
      "adding fully connected layers with 64 outputs\n",
      "adding fully connected layers with 32 outputs\n",
      "adding final layer with 1 output\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_data_node = tf.placeholder(tf.float32, shape=(batch_size, num_input))\n",
    "eval_data = tf.placeholder(tf.float32, shape=(batch_size, num_input))\n",
    "logits = model_slim(train_data_node, architecture)\n",
    "train_labels_node = tf.placeholder(tf.float32, shape=(batch_size))\n",
    "eval_prediction = model_slim(eval_data, architecture,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "Restoring model from /raid/dkj755/git-repos/ElemNet/elemnet/sample/sample_model\n",
      "INFO:tensorflow:Restoring parameters from /raid/dkj755/git-repos/ElemNet/elemnet/sample/sample_model\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "train_writer = tf.summary.FileWriter('summary', graph_def=sess.graph_def)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "model_path = os.getcwd() + '/sample/sample_model'\n",
    "assert  model_path is not None\n",
    "print('Restoring model from %s' % model_path)\n",
    "saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = data.shape[0]\n",
    "predictions = np.ndarray(shape=(size), dtype=np.float32)\n",
    "for begin in range(0, size, batch_size):\n",
    "    end = begin + batch_size\n",
    "    if end <= size:\n",
    "        # predictions[:,begin:end] \\\n",
    "        outputs = sess.run(eval_prediction, feed_dict={eval_data: data[begin:end, ...]})\n",
    "        predictions[begin:end] = outputs\n",
    "    else:\n",
    "        outputs = sess.run(eval_prediction, feed_dict={eval_data: data[-batch_size:, ...]})\n",
    "        predictions[-batch_size:] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33150914 -1.911143   -1.3807236 ]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
